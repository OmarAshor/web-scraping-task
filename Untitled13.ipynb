{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EclJtHLfERKo",
        "outputId": "081a2b79-9afd-46d3-e00a-c205d42e9473"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetched page. First heading / title: Web Scraping Task with Form\n"
          ]
        }
      ],
      "source": [
        "# Step 0 — Setup & fetch page\n",
        "!pip install beautifulsoup4 requests lxml --quiet\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv, json, re, os\n",
        "\n",
        "url = \"https://baraasalout.github.io/test.html\"\n",
        "resp = requests.get(url)\n",
        "resp.raise_for_status()  # لو حصل خطأ في الشبكة سيوقف هنا\n",
        "html = resp.text\n",
        "soup = BeautifulSoup(html, \"lxml\")\n",
        "\n",
        "# تفقد سريع\n",
        "title = soup.title.string if soup.title else soup.find(['h1','h2']).get_text(strip=True)\n",
        "print(\"Fetched page. First heading / title:\", title)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 — Extract headings and p/li, save CSV\n",
        "rows = []\n",
        "\n",
        "# headings\n",
        "for tag in soup.find_all(['h1','h2']):\n",
        "    rows.append({'type': tag.name, 'text': tag.get_text(strip=True)})\n",
        "\n",
        "# paragraphs and list items\n",
        "for tag in soup.find_all(['p','li']):\n",
        "    text = tag.get_text(\" \", strip=True)\n",
        "    if text:\n",
        "        rows.append({'type': tag.name, 'text': text})\n",
        "\n",
        "csv_file = \"Extract_Text_Data.CSV\"\n",
        "with open(csv_file, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=['type','text'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(rows)\n",
        "\n",
        "print(f\"Saved {csv_file} ({len(rows)} rows).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVKwSIRJEVz6",
        "outputId": "d56bcb4f-4263-4809-f27b-fe0d122ea64f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Extract_Text_Data.CSV (34 rows).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2 — Extract table data (product, price, in stock) -> CSV\n",
        "table_rows = []\n",
        "table = soup.find('table')\n",
        "if table:\n",
        "    # لو في table حنعمل parsing عادي\n",
        "    headers = [th.get_text(strip=True) for th in table.find_all('th')]\n",
        "    for tr in table.find_all('tr'):\n",
        "        cells = [td.get_text(strip=True) for td in tr.find_all(['td','th'])]\n",
        "        if len(cells) >= 3 and cells[0].lower() != 'product':\n",
        "            table_rows.append({'Product': cells[0], 'Price': cells[1], 'In Stock': cells[2]})\n",
        "else:\n",
        "    # fallback: parse the text block under \"Product Table\"\n",
        "    text = soup.get_text(\"\\n\")\n",
        "    m = re.search(r'Product Table(.*?)(?:Watch This Video|Product Information)', text, re.S)\n",
        "    if m:\n",
        "        lines = [l.strip() for l in m.group(1).splitlines() if l.strip()]\n",
        "        for line in lines:\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 3 and parts[0].lower() != 'product':\n",
        "                product = \" \".join(parts[:-2])\n",
        "                price = parts[-2]\n",
        "                stock = parts[-1]\n",
        "                table_rows.append({'Product': product, 'Price': price, 'In Stock': stock})\n",
        "\n",
        "csv_table = \"Extract_Table_Data.CSV\"\n",
        "with open(csv_table, 'w', newline='', encoding='utf-8') as f:\n",
        "    writer = csv.DictWriter(f, fieldnames=['Product','Price','In Stock'])\n",
        "    writer.writeheader()\n",
        "    writer.writerows(table_rows)\n",
        "\n",
        "print(f\"Saved {csv_table} ({len(table_rows)} rows).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyujVhZCEYAb",
        "outputId": "d9ee5d68-6b74-4c61-f338-a43170730ab0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Extract_Table_Data.CSV (3 rows).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3 — Extract product/book cards -> Product_Information.JSON\n",
        "books = []\n",
        "# نبحث عن عنوان القسم ثم نقرأ العناصر الموجودة بعده حتى نصل لعنوان القسم التالي\n",
        "section = soup.find(lambda t: t.name in ['h1','h2','h3'] and 'Product Information' in t.get_text())\n",
        "if section:\n",
        "    node = section.find_next_sibling()\n",
        "    buffer_text = \"\"\n",
        "    # نجمع النصوص التي تحتوي \"Add to basket\" لأنها تفصل الكروت\n",
        "    while node and 'Featured Products' not in node.get_text():\n",
        "        text = node.get_text(\"\\n\", strip=True)\n",
        "        if 'Add to basket' in text:\n",
        "            # إذا وجدنا Add to basket نفك البلوك إلى كروت\n",
        "            parts = text.split('Add to basket')\n",
        "            for p in parts:\n",
        "                p = p.strip()\n",
        "                if not p:\n",
        "                    continue\n",
        "                # نبحث عن السعر (جنيه أو $) واسم الكتاب وسطر التوفر\n",
        "                title = None; price = None; stock = None\n",
        "                lines = [l.strip() for l in p.splitlines() if l.strip()]\n",
        "                if lines:\n",
        "                    title = lines[0]\n",
        "                    for ln in lines[1:]:\n",
        "                        if re.search(r'£\\d+|\\$\\d+', ln):\n",
        "                            price = ln\n",
        "                        if 'In stock' in ln or 'Out stock' in ln or 'Out of stock' in ln or '✔' in ln:\n",
        "                            stock = ln\n",
        "                books.append({'title': title, 'price': price, 'stock': stock, 'button': 'Add to basket'})\n",
        "        node = node.find_next_sibling()\n",
        "\n",
        "# save JSON\n",
        "with open('Product_Information.JSON','w',encoding='utf-8') as f:\n",
        "    json.dump(books, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved Product_Information.JSON ({len(books)} items).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZd-McCpEbBa",
        "outputId": "84169f47-5358-43cf-d4c2-0aa1af63f479"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Product_Information.JSON (4 items).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4 — Extract form inputs -> Form_Details.JSON\n",
        "inputs = []\n",
        "forms = soup.find_all('form')\n",
        "if forms:\n",
        "    for form in forms:\n",
        "        for inp in form.find_all(['input','select','textarea']):\n",
        "            name = inp.get('name') or inp.get('id') or \"\"\n",
        "            tag = inp.name\n",
        "            type_ = inp.get('type') if tag == 'input' else tag\n",
        "            default = inp.get('value') or inp.get('placeholder') or \"\"\n",
        "            inputs.append({'field_name': name, 'tag': tag, 'type': type_, 'default': default})\n",
        "else:\n",
        "    # fallback: ابحث عن أي input على الصفحة\n",
        "    for inp in soup.find_all('input'):\n",
        "        inputs.append({'field_name': inp.get('name') or inp.get('id') or \"\", 'tag':'input', 'type': inp.get('type') or 'text', 'default': inp.get('value') or \"\"})\n",
        "\n",
        "with open('Form_Details.JSON','w',encoding='utf-8') as f:\n",
        "    json.dump(inputs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved Form_Details.JSON ({len(inputs)} fields).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNapby5DEdeY",
        "outputId": "e351894d-f43f-4d99-ec11-9fdc7316356d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Form_Details.JSON (5 fields).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5 — Extract iframe/video link -> Media_Links.JSON\n",
        "media = {}\n",
        "iframe = soup.find('iframe')\n",
        "if iframe and iframe.get('src'):\n",
        "    media['iframe_src'] = iframe.get('src')\n",
        "else:\n",
        "    video = soup.find('video') or soup.find('source')\n",
        "    if video and video.get('src'):\n",
        "        media['video_src'] = video.get('src')\n",
        "\n",
        "with open('Media_Links.JSON','w',encoding='utf-8') as f:\n",
        "    json.dump(media, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(\"Saved Media_Links.JSON:\", media)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z15yBBxuEgS9",
        "outputId": "0c352d02-dddf-4a45-8944-a84792ff6e92"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Media_Links.JSON: {'iframe_src': 'https://www.youtube.com/watch?v=ujf9RNuBdCU'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6 — Featured Products challenge -> Featured_Products.json\n",
        "featured_items = []\n",
        "section = soup.find(lambda t: t.name in ['h1','h2','h3'] and 'Featured Products' in t.get_text())\n",
        "if section:\n",
        "    node = section.find_next_sibling()\n",
        "    while node:\n",
        "        text = node.get_text(\" \", strip=True)\n",
        "        if text and 'Add to Basket' in text:\n",
        "            # parse simple pattern: name, price, colors\n",
        "            # مثال نصي: \"Wireless Headphones $49.99 Available colors: Black, White, Blue Add to Basket\"\n",
        "            m = re.search(r'^(.*?)\\s*(\\$\\d+(?:[.,]\\d+)?)\\s*Available colors:\\s*(.*?)\\s*Add to Basket', text, re.I)\n",
        "            if m:\n",
        "                featured_items.append({'name': m.group(1).strip(), 'price': m.group(2).strip(), 'colors': m.group(3).strip()})\n",
        "        node = node.find_next_sibling()\n",
        "\n",
        "# Fallback: search for span.name etc.\n",
        "for parent in soup.find_all(attrs={\"data-id\": True}):\n",
        "    pid = parent.get(\"data-id\")\n",
        "    name_span = parent.find('span', class_='name')\n",
        "    price_span = parent.find('span', class_='price')\n",
        "    colors_span = parent.find('span', class_='colors')\n",
        "    if name_span:\n",
        "        featured_items.append({\n",
        "            'id': pid,\n",
        "            'name': name_span.get_text(strip=True),\n",
        "            'price': price_span.get_text(strip=True) if price_span else '',\n",
        "            'colors': colors_span.get_text(strip=True) if colors_span else ''\n",
        "        })\n",
        "\n",
        "with open('Featured_Products.json','w',encoding='utf-8') as f:\n",
        "    json.dump(featured_items, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "print(f\"Saved Featured_Products.json ({len(featured_items)} items).\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rv-JMDRjEjTw",
        "outputId": "42c1580c-cb32-40fb-8678-740503f1e8b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Featured_Products.json (1 items).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uUQt4HsdElSF"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}